{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c658670140134133a7ef0485167aca2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_4400f2ac738c4fd792322f0fa7067d2d"
          }
        },
        "46383b7320db4cf78777d1b766005134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1fcdd8be13471dbc815b1a457010ea",
            "placeholder": "​",
            "style": "IPY_MODEL_0563273c06074f7f8d69a88c9d970ce2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "99cdbf5907344b70bbe5d02e665180b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_18210f6140b6478694e2d0ffac22ca87",
            "placeholder": "​",
            "style": "IPY_MODEL_45e535f3185d436e95a98a0fcacbdf55",
            "value": ""
          }
        },
        "2da8f4958bc242dfac7480f3264d3825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d873d4f9ae274cfd8a5657945bb435c9",
            "style": "IPY_MODEL_7e966f893b5e435498ea52e887b397fc",
            "value": true
          }
        },
        "f703b9f779ef425b96c0305e382c1fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bfccdc8a89e54195b0670c5db474f1dc",
            "style": "IPY_MODEL_e9ae11823c5245238b74acf174e8281a",
            "tooltip": ""
          }
        },
        "0a96707c0a214399b12cd69a7ea97672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862b343469c240d2bef10cf461579e99",
            "placeholder": "​",
            "style": "IPY_MODEL_ded659e119454d97998a75e7e3023c34",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "4400f2ac738c4fd792322f0fa7067d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "af1fcdd8be13471dbc815b1a457010ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0563273c06074f7f8d69a88c9d970ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18210f6140b6478694e2d0ffac22ca87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e535f3185d436e95a98a0fcacbdf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d873d4f9ae274cfd8a5657945bb435c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e966f893b5e435498ea52e887b397fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfccdc8a89e54195b0670c5db474f1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ae11823c5245238b74acf174e8281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "862b343469c240d2bef10cf461579e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded659e119454d97998a75e7e3023c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2b9f00835854ce7952cf00c6a2ee7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f872eed2115f41e9a614e553c730c910",
            "placeholder": "​",
            "style": "IPY_MODEL_357914ae817c411f9edd41b8c5fe5628",
            "value": "Connecting..."
          }
        },
        "f872eed2115f41e9a614e553c730c910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357914ae817c411f9edd41b8c5fe5628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_gradio.py\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import PeftModel\n",
        "import os\n",
        "import gc\n",
        "\n",
        "# --- Load HF Token using Colab Secrets ---\n",
        "hf_token = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    if hf_token:\n",
        "        print(\"HF_TOKEN retrieved successfully from Colab Secrets.\")\n",
        "    else:\n",
        "        print(\"WARNING: Colab Secret 'HF_TOKEN' found but might be empty or notebook access is disabled.\")\n",
        "except ImportError:\n",
        "    print(\"INFO: 'google.colab userdata' not found. This is expected if not running in Google Colab.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred trying to access Colab Secrets: {e}\")\n",
        "\n",
        "if not hf_token:\n",
        "    print(\"WARNING: Hugging Face token (HF_TOKEN) was not found. Model loading might fail if it's private/gated.\")\n",
        "# --- End Token Loading ---\n",
        "\n",
        "# Suppress less critical Hugging Face warnings\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# --- Configuration ---\n",
        "adapter_repo_id = \"sujoy0011/kiit-llama2-lora-adapters\"\n",
        "base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# --- Global Variables ---\n",
        "model = None\n",
        "tokenizer = None\n",
        "pipe = None\n",
        "compute_dtype = torch.float16 # Default\n",
        "model_loaded_successfully = False # Flag to track loading status\n",
        "\n",
        "# --- Model Loading Function ---\n",
        "def load_model_resources():\n",
        "    \"\"\"Loads the model, tokenizer, and creates the pipeline.\"\"\"\n",
        "    global model, tokenizer, pipe, compute_dtype, model_loaded_successfully\n",
        "\n",
        "    print(\"--- Starting Model Loading (Gradio/Colab) ---\")\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        raise gr.Error(\"CUDA is not available. Please ensure you selected a GPU runtime in Colab.\")\n",
        "\n",
        "    # Determine compute dtype\n",
        "    major, minor = torch.cuda.get_device_capability()\n",
        "    if major >= 8: compute_dtype = torch.bfloat16; dtype_msg = \"bfloat16\"\n",
        "    else: compute_dtype = torch.float16; dtype_msg = \"float16\"\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"GPU: {gpu_name}, Capability: compute_{major}{minor}. Using compute dtype: {dtype_msg}\")\n",
        "\n",
        "    # Quantization Config\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype, bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    # Load Base Model Quantized\n",
        "    print(f\"Loading base model: {base_model_name} quantized...\")\n",
        "    try:\n",
        "        model_base = AutoModelForCausalLM.from_pretrained(\n",
        "            base_model_name, quantization_config=bnb_config, device_map=\"auto\",\n",
        "            trust_remote_code=True, token=hf_token, low_cpu_mem_usage=True\n",
        "        )\n",
        "        print(\"Base model loaded.\")\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error loading base model: {e}\"\n",
        "        if \"RAM\" in str(e).upper(): error_msg += \"\\n\\nHint: Colab RAM limit?\"\n",
        "        elif \"authentication\" in str(e).lower(): error_msg += \"\\n\\nHint: Check HF Token/Login & Llama 2 terms.\"\n",
        "        print(error_msg)\n",
        "        raise gr.Error(f\"Failed to load base model. Error: {e}\")\n",
        "\n",
        "    # Load Tokenizer\n",
        "    print(f\"Loading tokenizer from adapter repo: {adapter_repo_id}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(adapter_repo_id, token=hf_token)\n",
        "        print(\"Tokenizer loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not load tokenizer from adapter repo ({e}). Loading from base model.\")\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(base_model_name, token=hf_token)\n",
        "            print(\"Loaded tokenizer from base model instead.\")\n",
        "        except Exception as e_base_tok:\n",
        "             print(f\"Error loading tokenizer: {e_base_tok}\")\n",
        "             raise gr.Error(f\"Failed to load tokenizer. Error: {e_base_tok}\")\n",
        "\n",
        "    # Load LoRA Adapters\n",
        "    print(f\"Loading LoRA adapters from repo: {adapter_repo_id}...\")\n",
        "    try:\n",
        "        model = PeftModel.from_pretrained(model_base, adapter_repo_id, token=hf_token, device_map='auto')\n",
        "        print(\"LoRA adapters loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error loading LoRA adapters from {adapter_repo_id}: {e}\"\n",
        "        if \"RAM\" in str(e).upper(): error_msg += \"\\n\\nHint: RAM limit?\"\n",
        "        elif \"adapter_config.json\" in str(e): error_msg += f\"\\n\\nHint: Check '{adapter_repo_id}'.\"\n",
        "        print(error_msg)\n",
        "        raise gr.Error(f\"Failed to load LoRA adapters. Error: {e}\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Set up Generation Pipeline\n",
        "    print(\"Setting up text generation pipeline...\")\n",
        "    try:\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\", model=model, tokenizer=tokenizer,\n",
        "            torch_dtype=compute_dtype, device_map=\"auto\"\n",
        "        )\n",
        "        print(\"Pipeline ready.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating pipeline: {e}\")\n",
        "        raise gr.Error(f\"Failed to create generation pipeline. Error: {e}\")\n",
        "\n",
        "    print(\"--- Model loading and pipeline setup complete. ---\")\n",
        "    model_loaded_successfully = True # Set flag\n",
        "    return True\n",
        "\n",
        "# --- Initial Model Load ---\n",
        "model_loaded_successfully = False\n",
        "try:\n",
        "    print(\"Attempting initial model load...\")\n",
        "    load_model_resources()\n",
        "except Exception as e:\n",
        "    print(f\"FATAL: Initial model loading failed: {e}\")\n",
        "\n",
        "# --- Inference Function ---\n",
        "def generate_kiit_response(user_prompt):\n",
        "    global pipe, tokenizer, model_loaded_successfully\n",
        "    if not model_loaded_successfully or pipe is None or tokenizer is None:\n",
        "        return \"Error: Model resources not loaded. Check logs.\"\n",
        "\n",
        "    print(f\"\\nGenerating response for prompt: {user_prompt[:100]}...\")\n",
        "    system_prompt = \"You are a helpful assistant knowledgeable about Kalinga Institute of Industrial Technology (KIIT). Provide concise and accurate information based on the user's question about KIIT.\"\n",
        "    llama_prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_prompt} [/INST]\"\n",
        "\n",
        "    try:\n",
        "        sequences = pipe(\n",
        "            llama_prompt, do_sample=True, top_k=10, num_return_sequences=1,\n",
        "            eos_token_id=tokenizer.eos_token_id, max_new_tokens=350,\n",
        "        )\n",
        "        generated_text = sequences[0]['generated_text']\n",
        "        response_part = generated_text.split('[/INST]')[-1].strip()\n",
        "        if response_part.endswith(tokenizer.eos_token):\n",
        "            response_part = response_part[:-len(tokenizer.eos_token)].strip()\n",
        "        if not response_part: response_part = \"Sorry, I couldn't generate a specific response.\"\n",
        "        print(f\"Generated response: {response_part[:100]}...\")\n",
        "        return response_part\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text generation: {e}\")\n",
        "        return f\"Sorry, an error occurred during generation: {e}\"\n",
        "\n",
        "# --- Gradio Interface Definition ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    # --- UI Title/Description ---\n",
        "    gr.Markdown(\"# KIITGPT Chatbot\")\n",
        "    gr.Markdown(\"Chatbot powered by Llama-2-7B, fine-tuned with LoRA on KIIT information.\")\n",
        "    # --- End UI Title/Description ---\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Chat History\", height=350)\n",
        "    msg = gr.Textbox(label=\"Your Question\", placeholder=\"Type your question about KIIT here...\")\n",
        "    clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "        user_message = history[-1][0]\n",
        "        try:\n",
        "            bot_message = generate_kiit_response(user_message)\n",
        "        except gr.Error as e: bot_message = f\"Error: {e}\"\n",
        "        except Exception as e: bot_message = f\"Unexpected error: {e}\"\n",
        "        history[-1][1] = bot_message\n",
        "        return history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "    clear.click(lambda: [], None, chatbot, queue=False)\n",
        "\n",
        "    # --- Footer ---\n",
        "    footer_html = \"\"\"\n",
        "    <div style=\"text-align: center; margin-top: 20px; font-size: small; color: #888;\">\n",
        "        Made with ❤️ by <a href=\"https://www.linkedin.com/in/dutta-sujoy/\" target=\"_blank\" style=\"color: #007bff; text-decoration: none;\">Sujoy</a>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    gr.HTML(footer_html)\n",
        "    # --- End Footer ---\n",
        "\n",
        "\n",
        "# --- Launch the Interface ---\n",
        "if __name__ == \"__main__\":\n",
        "    if not model_loaded_successfully or pipe is None:\n",
        "        print(\"\\nWARNING: Model not loaded correctly. UI launching, but generation will fail.\")\n",
        "    else:\n",
        "        print(\"\\nModel loaded. Launching Gradio interface...\")\n",
        "    demo.launch(debug=True, share=True) # share=True for Colab public URL\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mby5OELqgmFP",
        "outputId": "e13943fd-4a52-44d0-cac1-3e5dcff3e5fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app_gradio.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio torch transformers accelerate bitsandbytes peft sentencepiece huggingface_hub importlib-metadata\n"
      ],
      "metadata": {
        "id": "p1aZPNwFgn5j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# Paste your token (hf_...) with 'read' access (or 'write' if needed later).\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c658670140134133a7ef0485167aca2a",
            "46383b7320db4cf78777d1b766005134",
            "99cdbf5907344b70bbe5d02e665180b1",
            "2da8f4958bc242dfac7480f3264d3825",
            "f703b9f779ef425b96c0305e382c1fc3",
            "0a96707c0a214399b12cd69a7ea97672",
            "4400f2ac738c4fd792322f0fa7067d2d",
            "af1fcdd8be13471dbc815b1a457010ea",
            "0563273c06074f7f8d69a88c9d970ce2",
            "18210f6140b6478694e2d0ffac22ca87",
            "45e535f3185d436e95a98a0fcacbdf55",
            "d873d4f9ae274cfd8a5657945bb435c9",
            "7e966f893b5e435498ea52e887b397fc",
            "bfccdc8a89e54195b0670c5db474f1dc",
            "e9ae11823c5245238b74acf174e8281a",
            "862b343469c240d2bef10cf461579e99",
            "ded659e119454d97998a75e7e3023c34",
            "f2b9f00835854ce7952cf00c6a2ee7fe",
            "f872eed2115f41e9a614e553c730c910",
            "357914ae817c411f9edd41b8c5fe5628"
          ]
        },
        "id": "AvguDz4ziZdq",
        "outputId": "93169bce-d5b6-4fff-87bd-b59da609a9cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c658670140134133a7ef0485167aca2a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app_gradio.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f7cFDP9grCD",
        "outputId": "66e30552-3a31-4a60-f63a-2230666ea10e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-18 11:22:25.919177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744975345.940034    9908 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744975345.946273    9908 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 11:22:25.967477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "An unexpected error occurred trying to access Colab Secrets: 'NoneType' object has no attribute 'kernel'\n",
            "WARNING: Hugging Face token (HF_TOKEN) was not found. Model loading might fail if it's private/gated.\n",
            "Attempting initial model load...\n",
            "--- Starting Model Loading (Gradio/Colab) ---\n",
            "GPU: Tesla T4, Capability: compute_75. Using compute dtype: float16\n",
            "Loading base model: meta-llama/Llama-2-7b-chat-hf quantized...\n",
            "Loading checkpoint shards: 100% 2/2 [01:06<00:00, 33.41s/it]\n",
            "Base model loaded.\n",
            "Loading tokenizer from adapter repo: sujoy0011/kiit-llama2-lora-adapters...\n",
            "Tokenizer loaded.\n",
            "Loading LoRA adapters from repo: sujoy0011/kiit-llama2-lora-adapters...\n",
            "LoRA adapters loaded successfully.\n",
            "Setting up text generation pipeline...\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
            "Pipeline ready.\n",
            "--- Model loading and pipeline setup complete. ---\n",
            "/content/app_gradio.py:181: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Chat History\", height=350)\n",
            "\n",
            "Model loaded. Launching Gradio interface...\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://c69c23452c79f04064.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\n",
            "Generating response for prompt: hi...\n",
            "Generated response: KIIT offers 150+ programs in engineering, management, law, and medicine. 2024 intake: 10,000+ studen...\n",
            "\n",
            "Generating response for prompt: what is kiit...\n",
            "Generated response: KIIT University. 12 schools. 150+ programs. 2024 QS Global Employability Rank 125....\n",
            "\n",
            "Generating response for prompt: full name of kiit...\n",
            "Generated response: Kalinga Institute of Industrial Technology. Established 1992. UGC-AICTE-DEC accredited. 12,000+ stud...\n",
            "\n",
            "Generating response for prompt: who is the founder of kiit...\n",
            "Generated response: Dr. Achyuta Samanta founded KIIT in 1992. He is anellected as MP in 2019 and serves as Education Min...\n",
            "\n",
            "Generating response for prompt: what are the courses available in kiit ...\n",
            "Generated response: 145+ programs including BTech, MBA, and PhDs in engineering, management, and law. 45% international ...\n",
            "\n",
            "Generating response for prompt: kiit address ...\n",
            "Generated response: KIIT Deemed University: Bhubaneswar, Odisha 751024. 10km from Biju Patnaik Airport....\n",
            "\n",
            "Generating response for prompt: kiit address...\n",
            "Generated response: KIIT City, Bhubaneswar, Odisha. 752040. 12km from Biju Patnaik Airport....\n",
            "\n",
            "Generating response for prompt: what is kiit...\n",
            "Generated response: KIIT is a deemed university with 12 schools and 65 UG programs. 15,000+ students from 80 countries. ...\n",
            "\n",
            "Generating response for prompt: full name of kiit...\n",
            "Generated response: Kalinga Institute of Industrial Technology. 16,000+ students enrolled. 15 schools across engineering...\n",
            "\n",
            "Generating response for prompt: who is the founder of kiit...\n",
            "Generated response: Dr. Achyuta Samanta, Odisha CM from 1995-1999. Established KISS tribal university in 1992....\n",
            "\n",
            "Generating response for prompt: kiit address...\n",
            "Generated response: Main Campus: Plot No. 1, KIIT Road, Patia, Bhubaneswar, Odisha. 751024....\n",
            "\n",
            "Generating response for prompt: what are the courses offer ny the kiit...\n",
            "Generated response: 45 UG/PG programs in engineering, management, law, and social sciences. 60+ specializations in areas...\n",
            "\n",
            "Generating response for prompt: how to get admission in kiit for cse b.tch ...\n",
            "Generated response: GATE/JEE score 80%+. 5% seat reserved for KIITEE. 2024: 12,000+ applications....\n",
            "\n",
            "Generating response for prompt: what is kiit...\n",
            "Generated response: KIIT is a public deemed university in Odisha. Ranked 301-400 QS Global University Rankings. 45,000+ ...\n",
            "\n",
            "Generating response for prompt: kiit full name...\n",
            "Generated response: Kalinga Institute of Industrial Technology. Established 1992 as KIIT University....\n",
            "\n",
            "Generating response for prompt: what is kiit nirf rank...\n",
            "Generated response: 84.6/100 (NIRF 2024). 4th in Odisha and 151st in India....\n",
            "\n",
            "Generating response for prompt: what is the address of kiit...\n",
            "Generated response: KIIT-TBI Campus: 1645, Kalinga Industrial Estate, Patia Road, Bhubaneswar, Odisha. 751024....\n",
            "\n",
            "Generating response for prompt: who is the founder of kiit...\n",
            "Generated response: Dr. Achyut Samant (1992). Former Odisha CM and KIIT Chancellor. 2024: Established 12 AI labs in 12 c...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2982, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app_gradio.py\", line 218, in <module>\n",
            "    demo.launch(debug=True, share=True) # share=True for Colab public URL\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2888, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2986, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c69c23452c79f04064.gradio.live\n"
          ]
        }
      ]
    }
  ]
}